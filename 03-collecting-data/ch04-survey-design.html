<section data-type="chapter" class="green">
  <header>
    <div class="icon">
      <img src="../images/sections/03/survey.png" />
    </div>
    <p>Chapter 4</p>
    <h1>Intro to Survey Design</h1>
  </header>

  <section data-type="sect1">

  <p>Most people think doing a survey is as simple as writing a bunch of questions and asking people to answer them. Easy, right? Sort of. If you want to collect the best data possible, survey design can get a little more complicated, but don’t worry. We’ll go over a few key elements to help you get started.</p>

    <h1>Purpose of a Survey</h1>

    <p>A well-formulated survey should allow you to collect accurate and verifiable data about your topic of interest so you can make claims that are concrete rather than speculative. To do this, it is important to clearly identify the purpose(s) of your survey before creating it so you know what information to obtain from your respondents.</p>

    <p>Let’s say you’re a media tycoon trying to improve your television viewing profits, and you want to know how many people are watching their favorite programs on the internet.  You decide the main question and purpose of your survey are:</p>

    <table class="custom question-and-answer">
      <tr>
        <th>Research Question</th>
        <th>Purpose</th>
      </tr>
      <tr>
        <td><em>What percentage of television viewers watch their favorite tv shows online?</em></td>
        <td><h2>Describe a variable</h2><p>The percent of people who watch television programs online.</p></td>
      </tr>
    </table>

    <p>After thinking about it, you realize that it would be beneficial to get some more details, so you add a few purposes to your survey:</p>

    <table class="custom question-and-answer">
      <tr>
        <th>Research Question</th>
        <th>Purpose</th></tr>
      <tr>
        <td><em>Do younger television users tend to stream more television programs online than older viewers?</em></td>
        <td>
          <h2>Describe a relationship between variables</h2>
          <p>Which age group is more likely to watch television programs online?</p>
        </td>
     </tr>
     <tr>
       <td><em>If one group watches more programs online, why? </em></td>
       <td>
         <h2>Explain a relationship</h2>
         <p>What makes one group more likely to prefer online viewing than the other group?</p>
       </td>
     </tr>
     <tr>
       <td><em>How can we make online viewership profitable (or more profitable, if it already is0?</em></td>
       <td>
         <h2>Influence something</h2>
         <p>What do we need to do to change things?</p>
       </td>
     </tr>
   </table>
    
    <p>Here are a few questions to ask yourself as you are refining the purpose of your survey:</p>

    <ul>
      <li>What are you trying to achieve with this survey?</li>
      <li>What do you want to know precisely?</li>
      <li>Why is this important to know?</li>
      <li>Is there other information that could be useful? Why?</li>
      <li>Is conducting a survey the right method for the data you want to collect? (see <a href="#">Additional data collection methods</a>)</li>
    </ul>
    
    <div data-type="warning">
      <p>Data and numbers can be very powerful, but sometimes people conduct surveys for the wrong reasons. You will miss the opportunity to gain serious insight or obtain meaningful information with your survey if:</p>

      <ul>
        <li>You don’t really care about the results. You just want to show people that you’ve got numbers.</li>
        <li>You misuse the data collected.</li>
        <li>You are more concerned about how people will receive your findings than having reliable results.</li>
        <li>You have already determined what the results should be.</li>
      </ul>
    </div>

    <p>Remember, we do research to gain insight and test hypotheses. That means it’s important to try and collect the most accurate and representative data possible.</p>

    <h2>Self-Administered and Administered Surveys</h2>

    <p>Before discussing different types of surveys, let’s quickly talk about the difference between a self-administered and an administered survey. Self-administered simply means that respondents fill out a questionnaire themselves, like with online or mail surveys. They can be useful if you have a limited budget or want to reach people over a wide geographic area.</p>

    <p>However, these types of surveys are most easily delivered to those who can read and write, so this may not be the best option if your target audience has vision impairments or limited literacy. Since there’s no survey administrator, there’s a higher risk of respondents misinterpreting questions. This is especially true when the survey is written in a language that’s not the respondent’s primary language, or when a survey is translated, since some translations may not properly convey the intent of a question.  Also, if you want to include a method for verifying respondents’ identities (perhaps to prevent someone from taking the survey twice), it can add effort and cost.
</p>

    <table class="custom good-and-bad">
      <tr>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
      <tr>
        <td>
          <ul>
            <li>Good for limited budgets</li>
            <li>Large geographic reach</li>
            <li>Respondents can answer on their own time</li>
          </ul>
        </td>
        <td>
          <ul>
            <li>More difficult to distribute to populations with limited ability to read or write</li>
            <li>Risk of respondents misinterpreting questions</li>
            <li>Risk of lower completion rate</li>
            <li>Require extra effort to verify that the respondent was actually the person who completed the survey </li>
          </ul>
        </td>
      </tr>
    </table>

    <p>In an administered survey, an interviewer asks the questions. You can conduct them face-to-face, by phone, or online. Administered surveys can offer better quality control and the possibility to collect more in-depth information, since interviewers can clarify questions or probe respondents for more details. However, administered surveys are often more expensive and time-consuming than self-administered surveys, especially when considering the time needed to train interviewers and collect more exhaustive data.</p>
<p>There is also the risk of an interviewer effect, where the interviewers themselves might influence the responses.  This could happen because of the way they ask questions or phrase explanations, or because of another social factor altogether: perhaps the interviewer looks like the respondent’s least favorite neighbor and the respondent unknowingly gives biased answers as a result! </p>
      <table class="custom good-and-bad">
        <tr>
          <th>Pros</th>
          <th>Cons</th>
        </tr>
        <tr>
          <td>
            <ul>
              <li>Tighter quality control</li>
              <li>Interviewers can clarify questions for respondents</li>
              <li>Can collects richer and more in-depth information</li>
              <li>Easier to reach specific or marginalized populations (ex: the elderly or the homeless)</li>
            </ul>
          </td>
          <td>
            <ul>
              <li>Can be expensive</li>
              <li>Can be time consuming</li>
              <li>Risk of interviewer effect (ex: an interviewer’s interpretation of a question could biases some of the results)</li>
            </ul>
          </td>
        </tr>
      </table>
    <h2>Self-administered survey types</h2>      
    <h3>Online and email surveys</h3>

    <p>One of the easiest and quickest ways you can conduct a survey is online. You can either have people fill out questionnaires directly on a website or send them a questionnaire via e-mail.  </p>

    <p>The website option is especially useful if you want to link participants to your survey through social media tools such as Twitter or Facebook. There are a number of survey sites that are “one stop shops,” enabling you to design questionnaire forms, collect data, and analyze responses in real-time at an affordable rate. If you only need to work with a small number of questions and responses, some free services might be sufficient. Certain sites also have additional features available; for example, many offer limited data validation and include a mobile version of your survey so people can respond whenever or wherever they want.You’ll find links to a few of these sites in the Resources appendix. {INSERT LINK HERE} </p>

    <div data-type="warning">Be aware that online survey platforms are often subject to the laws of the countries in which their websites are based. If you are dealing with sensitive data, be sure to read the Privacy Policies and Terms of Use before signing up.</div>

    <table class="custom good-and-bad">
      <tr>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
      <tr>
        <td>
          <ul>
            <li>Fairly fast results</li>
            <li>Can integrate support tools (ex: images, sounds, video)</li>
            <li>Relatively cheap method</li>
          </ul>
        </td>
        <td>
          <ul>
            <li>Limited to people who have access to the web.</li>
            <li>Sample can be self-selective</li>
          </ul>
        </td>
      </tr>
     </table>

    <p>Email surveys can be harder to disseminate than web surveys since you need people’s email addresses before you can send it out. However, they can be very useful when you want to target a group of people you already know and have email addresses for, like your clients or a group of company employees.</p>

    <p>One major pitfall of online and email surveys is that your respondent group is limited to people who have access to the Internet. Also, since these surveys are self-administered, people decide on their own if they want to respond to them.  You may encounter a sampling bias, since people who are more comfortable with computers might be more likely to complete the survey.  </p>

    <p>This doesn’t mean you shouldn’t use these kinds of surveys; almost all survey methods have biases. The extent of this bias varies depending on the survey type you use and the question you are trying to answer. Here’s an example:</p>

    <table class="custom yes-and-no">
      <tr>
        <th>Yes</th>
        <th>No</th>
      </tr>
      <tr>
        <td>We want to know if Internet users view television shows online more often than offline (e.g. on TV, DVD).</td>
        <td>We want to know if people in general watch television shows online more often than offline.</td>
      </tr>
    </table>

    <p>In this case, an online survey is a good option if you want to examine an online population, like in the statement on the left. They’re a poor option when we want to know about a whole population because we’re not likely to get a good response rate from people that have limited or no access to the Internet.</p>

    <h3>Mail surveys</h3>

    <p>Mail surveys are much like email surveys since they are self-administered, except that you are sending a paper version of the questionnaire by mail. They aren’t limited to the internet population, so may be a better choice if the group you’re trying to sample has limited computer access.  However, you must also take into consideration the costs of printing, paper, envelopes and postage, and since some people find it tedious to mail back a survey, you may end up with a lower response rate. Including a pre-addressed, stamped envelope with the survey can make responding more convenient and will often help improve your overall response rate.  </p>

<h2>Administered survey types</h2>
    <h3>Phone surveys</h3>

    <p>Phone surveys are a type of administered survey. Although they are often more costly than the self-administered surveys, they usually ensure higher quality control and are more adaptable, since a trained survey administrator will guide respondents through each question and can clarify any misunderstandings.</p>
    <p>Since respondents answer survey questions immediately, the overall data collection period for phone surveys can be shorter than mail or online surveys, but this depends on how many people  agree to complete the phone interview.  If you have a target number of responders to achieve and most people on your list hang up on you, it can take longer to collect data by phone!  </p>

    <table class="custom good-and-bad">
      <tr>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
      <tr>
        <td>Relatively fast results</td>
        <td>Higher costs</td>
      </tr>
    </table>

    <p>When doing surveys by phone, it helps if questions are short and concise so respondents understand them clearly. Interviewers cannot see the respondents, so both parties may miss non-verbal cues and interviewers cannot use visual props when asking questions. To avoid losing respondents’ attention, try to limit the expected time for completing the survey to 15-20 minutes.</p>

    <p>Before calling, you should have a reliable list of phone numbers.  You will also have to watch out for interviewer effects<span data-type="footnote">Likert scales were named after… you guessed it (!): its inventor, Rensis Likert, a psychologist who did a lot of survey research for his work.</span> in order to reduce biases in your survey.</p>

    <table class="custom yes-and-no">
      <tr>
        <th>Yes</th>
        <th>No</th>
      </tr>
      <tr>
        <td>We want to know what people think about the name of our new television station.</td>
        <td>We want to know if people think our new logo is appropriate to our brand message.</td>
      </tr>
    </table>

    <p>In the above example, a phone survey would be a good option because you could reach a large and general population. However, it’s not very useful in the second situation because the respondents can’t see the logo, making it difficult for them to give an opinion.</p>

    <h3>Face-to-face surveys</h3>

    <p>Face-to-face surveys share many of the same advantages, disadvantages and biases as phone surveys. However, unlike in phone surveys, the interviewer and respondent can also see each other and pick up on facial expressions and bodily cues. This can be helpful if one of the people is attempting to clarify a point, but it also results in the greater potential for an interviewer effect, since the respondent can be influenced by all aspects of the interviewer’s appearance and behavior rather than just their voice.</p>
<p>Face-to-face surveys are limited geographically if you want the interviewer and respondent to meet in person, but can also be conducted online using video conferencing software such as Skype or Google Hangouts. They can be particularly useful when you want to collect data from a very specific or hard-to-reach population, or when you want to conduct a really long survey.</p>
    <table class="custom good-and-bad">
      <tr>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
      <tr>
        <td>
          <ul>
            <li>Gets more in-depth information</li>
            <li>Useful to reach specific and hard to reach populations</li>
          </ul>
        </td>
        <td>
          <ul>
            <li>Expensive cost</li>
            <li>Interviewers effects</li>
            <li>Takes a long time</li>
          </ul>
        </td>
      </tr>
    </table>

    <p>Let’s review our previous example about watching TV shows online. Say we wanted to know the following details:</p>

    <ul>
      <li>How do families watch television programs in their homes?</li>
      <li>Which family members tend to watch TV online?</li>
      <li>What type of television program does each family member like to watch?</li>
      <li>Do they watch programs together?</li>
      <li>If so, what types of programs do they watch together? Do they ever fight about what to watch?</li>
    </ul>

    <p>In this case, a face-to-face survey would allow you to interview all the members of a household at the same time, enabling you to get more details on the dynamics of television watching in families.</p>

    <h1>Things to think about when choosing your survey type</h1>

    <p>As you can see, there are many types of surveys and each one has its pros, cons and biases. The decision about which to use depends on a number of factors.  Here are a few things to keep in mind.</p>

    
    <div data-type="note">
      <ul>
        <li><em>Sample limitations:</em> Whom are you trying to reach? People that are only online? People that are only offline? Both?</li>
        <li><em>Budget:</em> How much money do you have to conduct the survey? Some options are less expensive than others.</li>
        <li><em>Speed:</em> What is the timeframe of your project? Do you need your data in the next week, month, year?</li>
        <li><em>Level of detail:</em> How in-depth do you want your data to be? Certain types of surveys are better suited for asking numerous or detailed questions than others.</li>
        <li><em>Number of respondents:</em> Some survey topics need a large group of respondents in order for it be representative, others not so much. It is important that the survey type you choose can affect response rates. Make sure that it meets your survey goals. For example, you risk reducing response rates if you use an online survey to target seniors or if you use mail surveys to target young people online under 18 years old.</li>
        <li><em>Mixing it up:</em> If you have the time and resources to do so, consider using more than one type of survey. For example, you may want to do an online and mail version of a same survey to increase respondent rates and improve your sample. Or you may start by doing an online survey and then conduct a face-to-face survey afterwards to gain more insight from your online results.</li>
      </ul>
    </div>

    <h2>Designing your questionnaire</h2>

    <p>Once you’ve identified the purpose of your survey and chosen which type you will use, the next step is to design the questionnaire itself. In this section, we’ll look at the structure, layout and ordering of questions. We’ll also talk about some key things to keep in mind once you’re done.</p>

    <h3>Questionnaire structure</h3>

    <p>Do you remember when you were taught in grade school that every essay should have an introduction, body and conclusion? Questionnaires should also have a certain structure. The parts of a questionnaire are the introduction, main topic, transitions between topics, demographic questions, and conclusion.</p>

    <div data-type="note">
      <h3>Introduction</h3>
      <p>Always start your survey with a brief introduction which explains:</p>
      <ul>
        <li>the purpose of the survey</li>
        <li>who is conducting it</li>
        <li>the voluntary nature of the participant’s involvement</li>
        <li>the respect of confidentiality</li>
        <li>time required to complete the survey</li>
      </ul>
    </div>

    <div data-type="note">
      <h3>Main topic</h3>
      <p>Generally, it is best to start with easy questions and then move on to harder, or more specific questions.</p>
      <ul>
        <li>Ask about objective facts before asking more subjective questions.</li>
        <li>Order questions from the most familiar to least.</li>
        <li>Make sure that the answer for a question does not diminish the impact of the next one. There should be logic in the order.</li>
      </ul>
    </div>

    <div data-type="note">
      <h3>Transition between topics</h3>
      <p>To reduce boredom or lost of interest, use transitions between groups of questions to explain a new topic or format. For example:</p>
      <p>“The next few questions are related to the frequency of your TV viewing habits. Please choose the answer that best describes your situation.”</p>
    </div>

    <div data-type="note">
      <h3>Demographic questions</h3>
      <p>It is usually best to place demographic questions near the end of a survey, when people begin to get tired and start losing their focus. Typical demographic questions include:</p>
      <ul>
        <li>Age</li>
        <li>Income</li>
        <li>Nationality or Location</li>
        <li>Education</li>
        <li>Civil status</li>
        <li>Cultural background</li>
      </ul>
    </div>

    <div data-type="note">
      <h3>Conclusion</h3>
      <p>Thank the participant for their contribution and explain how it has been valuable to the project. Reiterate that their identity will be kept confidential and that results will be anonymized. If you wish, you can also:</p>
      <ul>
        <li>Include your contact information in case they have any additional questions related to the survey.</li>
        <li>Ask for their contact information if you are offering an incentive for completing the survey or if you are doing a follow-up survey.</li>
      </ul>
    </div>

    <p>If you contact respondents in advance to invite them to participate in the survey, you should also explain why they have been selected to participate, when the survey will take place and how they can access it.</p>

    <h2>General layout</h2>

    <p>There are a few good rules to follow when designing the general layout of your survey.</p>

    <ul>
      <li>Put your introduction and conclusion on separate pages from your questions.</li>
      <li>The format should be easy to follow and understand.</li>
      <li>Check that filter questions work as intended (see Dichotomous Questions for more information).</li>
      <li>In general, response rates tend to diminish as surveys become longer. Stick to questions that meet your goals, rather than just asking questions you think might be important.</li>
      <li>Leave enough space for respondents to answer open-ended questions.</li>
      <li>Make sure to include all likely answers for closed-ended questions, including an “other” option in case respondents feel that none of the provided answers suit them. Where appropriate, also include “Not Applicable” and a “Choose not to respond” options. (See Closed questions in Next Chapter)</li>
      <li>Ensure that questions flow well and follow a certain sequence of logic. Begin the survey with more general questions and then follow with more specific or harder issues. Finish with general demographic topics (e.g. age, gender, etc.), unless you are using demographic questions to screen for eligibility at the beginning of the survey.  Group questions by theme or topic.</li>
    </ul>

    <h2>A few more things to keep in mind...</h2>

    <h3>Consider your audience</h3>

    <p>Think about the people who will be participating in your survey. Let’s say that you want to do a survey in a school where many students have recently immigrated to the country as refugees with their families, and don’t speak the local language very well.
 </p>
    <ul>
      <li>In what language(s) should you conduct the survey? Should you only conduct the survey in the local language or instead prepare the survey in several languages?  If you’re preparing different versions of the survey, who will ensure consistency between the translations?</li>
      <li>What kind of vocabulary should you use? These are students, not professors. You will probably want to use fairly basic language, especially if many are not native speakers. We have not specified their age, but it would be useful to take this information into consideration when thinking about vocabulary.</li>
      <li>Is the use of certain colors, font or images appropriate or useful? In this case, images and fun fonts are probably very practical to engage with a young  target audience. However, it is important to consider cultural sensitivities. Certain images or use of colors could evoke negative thoughts or sentiments in people, especially from children who have suffered from traumatic events or who come from war-torn countries.</li>
    </ul>

    <h3>Word your instructions and questions clearly and specifically</h3>

    <p>It is important that your instructions and questions are simple and coherent. You want to make sure that everyone understands and interprets the survey in the same way. For example, consider the difference between the following two questions.</p>  
<ul><li>* When did you first notice symptoms? ______________________</li>
<li>* When did you first notice symptoms (e.g. MM/YYYY)?
__ __ / __ __ __ __.</li></ul>
<p>If you want the question to be open to interpretation so that people can give answers like, “after I came back from my last trip,” then the first option is okay.  However, if you’re really wondering how long each person has been experiencing symptoms, the second version of the question lets the respondent know that you’re specifically interested in the month and year the symptoms first occurred.  </p>

    <h3>Pay attention to length</h3>

    <p>We often want to collect as much information as possible when conducting a survey. However, extremely long surveys quickly become tedious to answer. Participants get tired or bored, which decreases the completion rate. After a while, you risk getting false answers from people who are trying to finish the survey as rapidly as possible. When reviewing your questionnaire, ask yourself, “Do I really need this question? Will it bring any valuable data that can contribute to my reason for doing this survey?”</p>

    <h3>Track progress</h3>

    <p>It's good to indicate the respondent’s progress as they advance through the survey. It gives them an idea of their progression and encourages them to continue on. In a self-administered survey, a progress bar such as the one below could be placed at the beginning of each new section or transition.</p>

    <figure><img src="../images/sections/03/progress-bar.png" alt="progress bar" /></figure>

    <p>In an administered survey, the interviewer can simply make statements such as:</p>
    <div data-type="example">
      <p>“We are halfway done.”</p>
      <p>“There are only two more sections left.”</p>
      <p>“Only a few more questions to answer.”</p>
    </div>

    <h3>Train interviewers</h3>

    <p>If you are conducting an administered survey, you will have to prepare your interviewers ahead of time, explain their tasks, and make sure that they understand all the questions properly. You may also want them to be supervised when they are first conducting the survey to monitor quality control and interviewer effects.</p>
    <h3>Pre-testing</h3>

    <p>Pre-testing means testing your survey with a few initial respondents before officially going out in the field. This allows you to get feedback to improve issues you might have with length, technical problems, or question ordering and wording. Sometimes this this step gets skipped if there’s a tight deadline to meet, but don’t underestimate the value of pre-testing. It can save a lot of time and money in the end.</p>

    <h3>Anonymizing responses and result</h3>

    <p>We briefly mentioned anonymization earlier when we talked about questionnaire structure. Sometimes, people are afraid to give an honest response for fear that it might be traced back to them. By anonymizing responses (i.e. not attaching any identifying information to a person' answers), you will get more accurate data while protecting the identity of your participants.  There are times when you may need to keep respondents’ contact information associated with their responses, like if you’ll be conducting a follow-up survey and will need to know what their initial answers were.  Be clear in your survey about whether you’re anonymizing responses or not so respondents know if you’re storing their contact information.</p>
    <div data-type="warning">You should always anonymize any results you present, whether you collect the data anonymously or not.   </div>

    <h3>Incentives</h3>

    <p>The use of incentives can be contentious. You want to encourage as many people as possible to participate in your survey, but you also don’t want people completing the survey just to get a reward, since they may have been giving arbitrary answers to finish it quickly.</p>

    <p>If the survey is very long and time consuming, consider giving a small reward or stipend if a respondent completes the questionnaire. If the survey is shorter, consider doing a prize drawing from respondents who complete the survey and provide their contact information.</p>
<div data-type="warning">If you're doing research under an Institutional Research Board (IRB), as is common at many academic institutions, check with your IRB office about their rules regarding the use of incentives. </div>
    <p>In the next chapter, we'll go over individual question types, but for further reading on survey types and structure, check out: <a href="http://www.statpac.com/surveys/index.htm#toc" target="_blank">Designing Surveys and Questionnaires</a></p>

    <h1>Questions</h1>

    <h2>Types of questions</h2>

    <p>Once you have chosen the type of survey you will conduct, you will have to start thinking about the types of questions you will use. There are all sorts of questions that you can employ. It all depends of course on what type of data you are looking to collect.</p>

    <h3>Open versus Closed questions (collecting qualitative versus quantitative data)</h3>

    <p>Open or open-ended questions are used when you want to collect qualitative data. These are normally employed when you want to get more details on a specific area. This means you ask the person a question without offering any specific answers from which to choose. This is often a good option to discover new aspects, reasons or phenomena you may have overlooked or did not know existed.</p>

    <p>Closed questions are just the opposite. Numerous answers are offered when asking the question. Closed questions are used when we want to measure something in a very specific way and we want to collect quantitative data.</p>

    <p>Let’s look at a new example. Pretend that you work for an ice cream parlour called Fictionals (yes, we made up the name). You want to know why some people do not go and buy ice cream at your store.  Here is how you could ask an open and closed question.</p>

    <figure><img src="../images/sections/03/open-vs-closed.png" alt="Open vs. Closed Questions" /></figure>

    <p>In the closed question, we offer the most probable reasons why people would not go eat ice cream at our store. However, you will notice that when we ask an open-ended question we gain new insight on why some people might not try our ice cream: it’s not because they don’t like ice cream or they don’t like us (or our product), it’s because they can’t eat it! With this new insight, Fictionals is able to offer a new type of ice cream and attract a clientele it once did not have.</p>

    <p>As you can see, there are advantages to asking open-ended questions. The problem is that it is tedious work to code qualitative data, even with the help of a computer program or application. When you think that most people will probably give more or less the same answers, you can combine an open and closed question to get the best results. Here is how the same question would look if you transformed it into a combined open and closed question:</p>

    <figure><img src="../images/sections/03/open-and-closed.png" alt="Closed/Open Question" /></figure>

    <h3>Dichotomous questions</h3>

    <p>Dichotomous questions are when there only two possible answers are given to a question. Here are some classic examples of dichotomous type questions:</p>

    <figure><img src="../images/sections/03/dichotomous.png" alt="dichotomous questions" /></figure>

    <div data-type="warning">
      <p>A large sequence of dichotomous questions (ex. true or false) in a survey can bore respondents, causing them to give random answers in order to finish sooner. Try to spread them out throughout your survey if you must use many.</p>
    </div>

    <p>Sometimes you will use dichotomous questions to determine if a respondent is suited to respond to a next question. This is called a filter or contingency question. Filters can get very complex, so try to limit the number of filter questions you use to two or three. Here’s an example:</p>

    <figure><img src="../images/sections/03/fictionals.png" alt="Fictional's Flow Chart" /></figure>

    <h3>Multiple choice questions</h3>

    <p>Anyone who has ever passed an exam has probably already answered a multiple-choice question. Sometimes in surveys we want the respondent to choose only one among several answers. In this case, we use <em>radio</em> buttons (or circles), which indicate to only choose one item. When we want the respondent to choose more than one option, we use a <em>checkbox</em> instead. Here is what it looks like in practice:</p>

    <figure><img src="../images/sections/03/radio-vs-checkbox.png" alt="Radio vs. Checkbox" /></figure>

    <h3>Scaled questions</h3>

    <p>Scaled questions are used to measure people’s attitudes, opinions, lifestyles and environments. There are many different types but the most commonly used are Likert[1]
    and sliding scales. The main difference between the two is that a Likert scale uses text categories while a sliding scale uses numbers.</p>

    <figure><img src="../images/sections/03/likert-vs-slider.png" alt="Likert vs. Slider Scale" /></figure>

    <p>In the example above, the same question is asked twice, once with a Likert scale and once with a sliding scale. Notice that in the Likert scale there are five categories while in the sliding scale there are seven. Normally in a scaled question we either use 5, 7 or 10-point scales.</p>

    <p>These are odd number scales that allow participants to agree, disagree or indicate their neutrality (a 10-point scale includes 0, making it an odd number scale). An even number scale, such as a 4 or 6-point scale,  only allows participants to agree or disagree. This is why the odd number scales are usually preferred, although there are times when you might want to to use an even number scale if you consider that there is no room for “neutrality” in the question or you want to obligate the respondent to choose one or the other. This is what we call a “forced question”.</p>

    <h3>Likert scale</h3>

    <p>Likert scales are usually limited to a five-category scale. This is because it is difficult to create a greater number of categories using text. The most common  Likert scales your will find are:</p>

    <ul>
      <li>
        <p><em>Opinions and attitudes:</em> “How much do you agree with…?”</p>
        <p>Possible answers: Strongly agree, agree, neither agree or disagree, disagree, strongly disagree.</p>
      </li>
      <li>
        <p><em>Frequency:</em> “How often do you…?”</p>
        <p>Possible answers: Always, often, sometimes, rarely, never.</p>
      </li>
      <li>
        <p><em>Quality:</em> “In general, how do you rate the quality of…?”</p>
        <p>Possible answers: Excellent, very good, good, fair, poor.</p>
      </li>
      <li>
        <p><em>Importance:</em> “How important would you say {topic} is…”</p>
        <p>Possible answers: Very important, important, somewhat important, not at all important.</p>
      </li>
    </ul>

    <h2>Sliding scale</h2>

    <p>A sliding scale is useful when you want to have a more accurate reading of the respondent’s answer and is most beneficial in an online survey. Some people think that sliding scales are better than Likert scales because they are more interactive for respondents, but this is specifically in an online context. Sliding scales are extremely practical when conducting a multi-lingual survey, as text categories are not always very easy to translate.</p>

    <figure><img src="../images/sections/03/sliding-scale.png" alt="sliding scale" /></figure>

    <div data-type="warning">
      <p>When creating a sliding scale, never forget to label the first and last points in your scale. Otherwise, your respondents may misinterpret your scale, creating errors in your data.</p>
    </div>

    <h2>Question wording</h2>

    <p>It is extremely important to think about how you word your questions when developing your survey. Here are a few key things to keep in mind:</p>

    <h3>Focus</h3>

    <p>Each question should be specific and only have one focus.</p>

    <div data-type="example">
      <p>How many times have you eaten ice cream in the last month?</p>
    </div>

    <p>This question focuses on one issue (frequency of ice cream eating) and is specific (a certain time period).</p>

    <div data-type="example" class="neutral">
      <p>Do you avoid eating ice cream because you are on a diet? [Answer: Yes, I avoid ice cream, but not because I am on a diet]</p>
    </div>

    <p>This question is bad because it focuses on two different issues. You should not use the word “and” if it is connecting two different ideas. Instead, you could use filter questions to obtain the desired information. For example:</p>

    <figure><img src="../images/sections/03/fictionals-flow-chart.png" alt="Fictional's Flow Chart" /></figure>

    <h3>Precision</h3>

    <p>Not everyone will interpret all words in the same way, even if they are simple. You can define terms with a lead-in built into the question. Try to reduce ambiguity and the use of double negatives.</p>

    <table class="custom yes-and-no">
      <tr>
        <th>Do</th>
        <th>Don’t</th>
      </tr>
      <tr>
        <td>
          <ul>
            <li>Have you eaten chocolate ice cream in the past month?</li>
            <li>Ice cream with peanuts should not be permitted.</li>
            <li>Ice cream vendors should not disclaim having a peanut-free shop.</li>
          </ul>
        </td>
        <td>
          <ul>
            <li>Rocky Road, Mint Chocolate Chip, Dutch Chocolate and Hot Fudge ice creams are Fictionals’ best sellers. Have you eaten any chocolate ice cream in the last month?</li>
            <li>Ice cream with peanuts should be banned.</li>
            <li>Ice cream vendors should accept to have a peanut-free shop.</li>
          </ul>
        </td>
      </tr>
    </table>

    <h3>Brevity</h3>

    <p>Your questions should be relatively short, except where additional wording is necessary to provide context or to clarify terminology.</p>

    <table class="custom yes-and-no">
      <tr>
        <th>Do</th>
        <th>Don’t</th>
      </tr>
      <tr>
        <td>Do: Please list your three favorite ice creams in order of preference.</td>
        <td>Don’t: Can you please tell us what ice cream flavors you like and what are your first, second and third favorite?</td>
      </tr>
    </table>
      
    <h3>Biased and leading questions</h3>

    <p>Biased or leading questions can easily skew your answers if you do not pay close attention to how you use words, especially strong ones. Avoid overemphasizing statements and keep an eye out for questions that create “social desirability effects” where people will answer according to what society views as “proper” or a desirable behavior.</p>

    <table class="custom yes-and-no">
      <tr>
        <th>Do</th>
        <th>Don’t</th>
      </tr>
      <tr>
        <td>Do you agree that all ice cream vendors in our city should offer peanut-free products?</td>
        <td>Do you agree that ice cream vendors that serve peanuts are a severe hazard for the well-being of our children?</td>
      </tr>
    </table>

    <p>Notice how the second question tries to bias the respondent by using strong or affective words such as “severe”, “hazard”, “well-being”, and “children”. Even the first one is a bit leading with the use of the word “all”. The better question would be:</p>

    <div data-type="example"><p>Do you agree that ice cream vendors in our city should offer peanut-free products?</p></div>

    <h3>A few final things...</h3>

    <p>Finally, there are few last things to consider when developing your survey questions:</p>

    <ul>
      <li>Be sure to vary the type of questions you use to keep your respondents engaged throughout the whole survey. Remember, don’t just use one type question (eg. true/false questions). You have a variety to choose from. So mix it up while keeping in mind that each type of question has a specific purpose.</li>
      <li>Also include a “Don’t know” or “Not applicable” option among your answers when it makes sense (usually in your multiple choice and yes-no questions). You will have more precise results and may actually come across some unexpected insight.</li>
      <li>Think about how certain words can have different interpretations and remember that meanings are often embedded in culture and language. Be sensitive to different cultures if you are examining several groups within a population.</li>
    </ul>
      <p>As you have noticed, there are many things to plan and reflect upon when designing a survey. We’ve only presented a very broad overview of survey design. You can find much more information online or at the library.</p>
      <p>It can seem long and daunting at first, but just remember that this is will be the foundation of your data analysis. If you get this step right, you will collect much better data and make the rest of your work much easier! Good luck!</p>

      <p>Rando references section - need to figure out how to handle these</p>
      <p>References:
 
Fink, A.  (2006). How to conduct surveys: A step-by-step guide (3rd ed.). Thousand
Oaks, California: Sage Publications, Inc. 
 
Gray, G., and Guppy, N. (2003). Successful Surveys: Research methods and practice (3rd
ed.). Scarborough, Ontario: Thomson Nelson. 
 
Division of Instructional Assessment Resources. Scaled Questions. Retrieved on March
1, 2014 from the University of Texas Web site: http://www.utexas.edu/academic/ctl/assessment/iar/teaching/plan/method/survey/responseScale.pdf
 
Dierckx, D. (August 21, 2012). The case of ´Likert Scales v. Slider Scales´ [blog post].
Retrieved on March 3, 2012 from https://www.checkmarket.com/2012/08/likert_v_sliderscales/ 

Fowler, Floyd, J. (2014) Survey Research Methods (5th ed.). Thousand Oaks, California: SAJE Publications, Inc. 
 
</p>

  </section>
</section>
