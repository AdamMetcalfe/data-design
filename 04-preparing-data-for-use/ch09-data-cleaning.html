<section class="violet" data-type="chapter">
<header>
<div class="icon"><img src="../images/sections/04/cleaning.png" /></div>

<p>Chapter 9</p>

<h1>Data Cleaning</h1>
</header>

<section data-type="sect1">
<p>Now that you have a prepped data set, you&rsquo;re ready to get it clean. &nbsp;What does that mean though? &nbsp;What exactly is clean data and what do we have to do get it that way?</p>

<p>Well, when we clean data, we&rsquo;re going through it and identifying incorrect information &ndash; wrong numbers, misspellings, etc. &ndash; and deciding whether to correct them (if they are correctable) or to remove them altogether. &nbsp;Like data preparation, many <a class="glossterm" target="_blank" href="glossary01.html#cleaning-data">data cleaning</a> tasks are a combination of computerized tasks and manual work, since it is important for you to review the potential errors the computer identifies to see if they are, in fact, errors. &nbsp;Some of the items your computer flags as problems may turn out to just be extreme observations so it&rsquo;s critical that you be involved in the process. &nbsp;Don&rsquo;t just automate it all or you risk the possibility of deleting valid data! &nbsp;</p>

<h2>So what do we do?</h2>

<p>Let&rsquo;s start with some of the most basic data cleaning procedures. &nbsp;We&rsquo;re going to use Excel in some of the visuals for these examples, but you can use any spreadsheet or data software to perform these procedures. &nbsp;A list of programs is available in Appendix YYY.</p>

<h2>Range checks</h2>

<p><a class="glossterm" target="_blank" href="glossary01.html#check-range">Range checks</a> are a very straightforward procedure that we use on numeric fields to see if any values in the data set are above or below the most extreme acceptable values for that variable. &nbsp;Let&rsquo;s use an example of homework scores. &nbsp;Pretend that you&rsquo;re a college professor and your teaching assistants entered the first set of homework scores for the semester. You want to make sure they entered everything correctly, so you go into the data set and sort by the column that contains the scores for the first homework, graded on a scale of 0-100. You see the first few rows.</p>

<p>&nbsp;</p>

<table>
	<tbody>
		<tr>
			<th>Student ID</th>
			<th>HW 1 Score</th>
		</tr>
		<tr>
			<td>679372531</td>
			<td>980</td>
		</tr>
		<tr>
			<td>673540288</td>
			<td>99</td>
		</tr>
		<tr>
			<td>674082892</td>
			<td>97</td>
		</tr>
		<tr>
			<td>673923590</td>
			<td>96</td>
		</tr>
	</tbody>
</table>

<p>&nbsp;</p>

<p>There is a score of 980, so one of the TAs probably accidentally typed a zero after a score that should have been 98. &nbsp;You would want to flag the record and ask the TAs what the actual score should have been. &nbsp;</p>

<p>Visual scans of data during range checks can also reveal other potential problems even within the official bounds of the data. &nbsp;</p>

<p>&nbsp;</p>

<table>
	<tbody>
		<tr>
			<th>Student ID</th>
			<th>HW 1 Score</th>
		</tr>
		<tr>
			<td>674472019</td>
			<td>78</td>
		</tr>
		<tr>
			<td>679029425</td>
			<td>75</td>
		</tr>
		<tr>
			<td>671822390</td>
			<td>74</td>
		</tr>
		<tr>
			<td>671278927</td>
			<td>9</td>
		</tr>
	</tbody>
</table>

<p>&nbsp;</p>

<p>Here, one score is much lower than the others and has a strange score value. &nbsp;In this situation, it is possible that the score should have been entered as a 90 instead. &nbsp;This is another record that would make sense to flag and check with the source record. &nbsp;This is a good example of why it is important to be personally involved in the data checking process for variables that carry a lot of weight, like student grades or primary outcome variables for research projects. &nbsp;However, hand-checking all the variables in a data set can be very time-consuming, especially if the data set is large and for items that aren&rsquo;t as critical like name spellings, it may not be as important. &nbsp;It is up to you to decide which variables require involved personal attention. &nbsp;</p>

<div data-type="warning">Range checks will work no matter what your range is. &nbsp;Maybe you&rsquo;re expecting a decimal between 0 and 1, or your variable is normal body temperature in Fahrenheit, so you&rsquo;re expecting mostly values between 97.0 and 99.0, allowing for people that run cold and hot. &nbsp;You can always look and see if there are values stored in that variable group that are too low or high.</div>

<p>You can also use &quot;Filter&quot; commands to check for all values that are outside the acceptable range of a variable. However, it doesn't catch values that are inside your range but that look &quot;off&quot; based on the rest of your data. Here, a a basic range <a class="glossterm" target="_blank" href="glossary01.html#filter ">filter</a> would detect the &quot;980&quot; score but not the &quot;9&quot; score. If you use filtering to do your range checks, it is a good idea to also use another method to look at the overall distribution of your data to catch any values that might seem &quot;strange&quot; in comparison to your other values.</p>

<h2>Spell check</h2>

<p>Spell Check is another basic check that you can use to find problems in your data set. &nbsp;We suggest doing this field by field rather than trying to do it across the whole data set at once. &nbsp;The reason for this is that a word that might be considered a misspelling in one variable could be a valid word for another variable. &nbsp;A good example of this is the first name field. &nbsp;If you have a data set with a first name field, many of those entries could trigger a spell check alert even though they are legitimate names. &nbsp;If instead you focus on a single field at a name, you can work more quickly through the data set to catch problems. &nbsp;In the example from the data preparation chapter where students were listing their major on a survey, say one of the students had just pulled an all-nighter and accidentally typed &ldquo;Mtahmeitcs instead of Mathematics.&rdquo; &nbsp;A spell check on the &ldquo;Major&rdquo; field in your data set would quickly identify the misspelling and you could change it to &ldquo;Math&rdquo; or &ldquo;Mathematics,&rdquo; depending on which controlled vocabulary term you chose. &nbsp;</p>

<h2>Pattern matching/Regular expressions</h2>

<p>Another slightly more advanced type of data check involves <a class="glossterm" target="_blank" href="glossary01.html#matching-pattern">pattern matching</a>. &nbsp;This is the sort of check that you can use, for example, to make sure all the entries in a field are an email address. &nbsp;This involves something called regular expressions (often shortened to regex), which give you a way of telling the computer, &ldquo;I only want things that look like {this} to be stored in that variable. &nbsp;Tell me if something in there doesn&rsquo;t look like {this}.&rdquo; &nbsp;The way that you indicate what {this} should be varies from program to program and can look a little complicated if you&rsquo;ve never worked with it before, but it&rsquo;s not bad once you get used to it. &nbsp;If you have ever used an asterisk (*) as a wildcard for searching, that&rsquo;s actually part of regex, so you already know a piece of it! &nbsp;There are some regular expressions resources on page YYY if you want to learn the syntax for it.</p>

<p>There are also pattern matching options in Excel and some advanced filter options that sometimes work even better. &nbsp;We have some resources of our own for this off the eBook site at {insert link here, I&rsquo;ll record this so we can add the link for this before the 10th, it&rsquo;s easy to show peeps how do but is just way too long and weird to explain in text.}&nbsp;</p>

<h2>Combination of fields</h2>

<p>You can also use combinations of fields to do data checking and this is sometimes very important and actually necessary because you have to look at all the fields together to tell if one or more of the fields are incorrect. &nbsp;If you do any of your banking online, you do this all the time without even realizing it. &nbsp;Your online bank record shows you several different fields that all have to make sense together, and if they don&rsquo;t, red flags immediately go up in your mind. &nbsp;You have the source of the transaction, the amount of the transaction, the unit of currency that it&rsquo;s in, if it&rsquo;s a credit or a debit, the date the transaction occurred and the total balance of your account afterwards. &nbsp;All of these items are part of a data set, and you&rsquo;re doing a check on that data set every time you pull up your account online to make sure everything looks okay. &nbsp;If the amount of transaction was different than what you were expecting or the total of your account after the transaction was off, you would mentally flag it and call the bank to see what was up. &nbsp;</p>

<p>It&rsquo;s the same with any other data set. &nbsp;There may be fields that have to make sense together. &nbsp;Imagine that you&rsquo;re working on a medical study of hospital patients and you&rsquo;re tracking the medications they take daily by using three separate fields for medication type, the amount of the medication in number and the unit of the medication. &nbsp;So, for example, if the data set read, &ldquo;Aspirin, 500, mg&rdquo; that would mean the patient took 500 mg of aspirin each day. &nbsp;Now imagine that you received a record that said, &ldquo;Morphine, 200, lbs.&rdquo; &nbsp;What would your reaction be? &nbsp;It&rsquo;s logical that a hospital patient would be taking morphine and 200mg is a reasonable dosage, so the number alone wouldn&rsquo;t raise flags, but even 1lb of morphine would kill someone so there&rsquo;s definitely a problem there. &nbsp;You would probably want to go back to the patient&rsquo;s record or to whoever entered the data to get the correct units. &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>

<p>If any of these fields are free response, there are an infinite number of combinations that you can receive. &nbsp; As such, you should go through your data set early and identify groups of variables like this that need to work together so you can check records periodically as they come in for problems. &nbsp;Again, since this can be a time-consuming process, you need to decide how critical the cleanliness of these particular fields is to your overall end result, be it a specific visualization, a statistical analysis, or a general report.</p>

<h2>What happens if we don&rsquo;t clean our data?</h2>

<p>Many of these procedures can be time-intensive so you have to decide which to employ and which variables it is important to scrub clean. So what if we just skip the data cleaning process altogether and leave the data dirty? &nbsp;The answer to that isn&rsquo;t easy because it all depends how dirty your data is in the first place. At best, you&rsquo;ll get lucky and your data will be minimally dirty and you won&rsquo;t have any real impact on your end report. At worst, your results will be incorrect due to errors in your data set that you could have potentially corrected if you had gone through data cleaning procedures.</p>

<p>If you got your data from another source and their programmers were overly intense about their data checking, your data might already be reasonably clean to start with. If that&rsquo;s the case, you might be able to ignore the cleaning process with little impact on your end product. However, until you at least go through the basic checks involved in data cleaning, there&rsquo;s no real way or you to know how clean or dirty your data is unless you get a report from the people you got the data from. If you collected the data yourself, the only way to know is to do the data checking. That said...</p>

<h2>Accept that most data sets are never 100% clean</h2>

<p>Data cleaning is just like house cleaning &ndash; you won&rsquo;t ever catch everything. As hard as you may try, you can&rsquo;t force people to input 100% correct data, and we make errors ourselves as we work with data. You of course want your data to be as accurate as possible, but there will always be a little dust in the corners so it&rsquo;s important to accept that data sets are never perfect and to develop a sense of &ldquo;good enough.&rdquo;</p>

<p>For example, you have a list of 100 contacts from your database of 100,000 contacts and you notice that 2 of the 1,000 have the first and last names together in one field. Do you take on a project of combing through and correcting all 100,000 records?</p>

<p>It depends.</p>

<p>You may make a formal decision that the data is clean enough for your purposes or this may be too dirty for how you&rsquo;re using the data. &nbsp;This really depends on the variable in question and what your intended end output is. &nbsp;If you&rsquo;re responsible for checking that students correctly reported their majors for an internal report and you think that there was a 0.01% error rate, that&rsquo;s probably of a much lower concern than if you&rsquo;re checking a variable that is of critical importance to a safety report and you think there a possibly of a 5% error rate. Over time, you&rsquo;ll get a better sense of how clean or dirty a data set is, relatively speaking, and how labor-intensive the cleaning process will be for a particular group of variables. &nbsp;At that point, it&rsquo;s good to consult the key stakeholders for the end product to see how much cleaning they agree is sensible to pursue. &nbsp;You should always aim to have your data as clean as possible but always remember that it won&rsquo;t be 100% finished and you should consider the cost of having messy data and getting it clean.</p>

<p>Data preparation and cleaning have costs. &nbsp;If you hire someone to do this work for you, the cost is financial. &nbsp;If you&rsquo;re going to do it yourself, it costs you or someone on your project time (and maybe a little sanity). &nbsp;So if you&rsquo;ll never use a phone number, fax number or need to refer to someone as Reverend, you may make the decision to delete those variables, stop collecting them, and not worry about their prep and cleaning steps in the future.&nbsp;</p>

<h2>After Data Cleaning:&nbsp;Please Be Kind and Document!</h2>

<p>Once we have our data perfectly clean we find ourselves with a new, completely different problem. How do other people know that we have not corrupted the data by making these changes? After all, the data might look completely different from the original source, even if no numbers were changed as we rearranged our information.</p>

<p>For that reason it's important to document your cleaning procedures. What was the source file? What was done to produce the final version? Documentation can take the form of a &lsquo;read me&rsquo; file, or you can include the script and let the code speak for itself. No matter what you choose, it's important to maintain the integrity of the data by documenting how it was changed. &nbsp;Anyone who works with the data in the future will thank you!</p>
</section>
</section>
